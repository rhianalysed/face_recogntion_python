{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f10ba60",
   "metadata": {},
   "source": [
    "# Face Comparison\n",
    "Testing to see if two different images return a True or False value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cf7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "img = cv2.imread(\"messi1.jpg\")\n",
    "rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_encoding = face_recognition.face_encodings(rgb_img)[0]\n",
    "\n",
    "img2 = cv2.imread(\"biden.jpg\")\n",
    "rgb_img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_encoding2 = face_recognition.face_encodings(rgb_img2)[0]\n",
    "\n",
    "# To know if img and img2 are the same person\n",
    "result = face_recognition.compare_faces([img_encoding], img_encoding2)\n",
    "print(\"Result:\", result)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow(\"Img\", img)\n",
    "cv2.imshow(\"Img 2\", img2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9a5162",
   "metadata": {},
   "source": [
    "# Testing the Activating Webcam Feature\n",
    "This opens the webcam when run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b262eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, img = video_capture.read()\n",
    "    cv2.imshow(\"face detection\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa2e339",
   "metadata": {},
   "source": [
    "# Live Webcam Facial Recognition with OpenCV\n",
    "Python Script for Live Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b2a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Function to draw boundaries around detected features\n",
    "def draw_boundary(img, classifier, scaleFactor, minNeighbors, color, text):\n",
    "    # Convert the image to grayscale\n",
    "    grey_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect features in the image using the provided classifier\n",
    "    features = classifier.detectMultiScale(grey_img, scaleFactor, minNeighbors)\n",
    "    \n",
    "    # List to store coordinates of the detected features\n",
    "    coords = []\n",
    "    \n",
    "    # Loop through the detected features and draw rectangles and text around them\n",
    "    for (x, y, w, h) in features:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(img, text, (x, y-4), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "        coords = [x, y, w, h]\n",
    "\n",
    "    return coords, img\n",
    "\n",
    "# Function to perform face detection on an image\n",
    "def detect(img, faceCascade):\n",
    "    # Dictionary of color codes for drawing boundaries (e.g., blue for face)\n",
    "    color = {\"blue\": (255, 0, 0), \"red\": (0, 0, 255), \"green\": (0, 255, 0)}\n",
    "    \n",
    "    # Use the draw_boundary function to draw face boundaries\n",
    "    coords, img = draw_boundary(img, faceCascade, 1.1, 10, color['blue'], \"Face\")\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Load the pre-trained Haar Cascade classifier for face detection\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Infinite loop to continuously capture frames and perform face detection\n",
    "while True:\n",
    "    # Read a frame from the video capture\n",
    "    _, img = video_capture.read()\n",
    "    \n",
    "    # Perform face detection on the current frame\n",
    "    img = detect(img, faceCascade)\n",
    "    \n",
    "    # Display the image with face boundaries\n",
    "    cv2.imshow(\"face detection\", img)\n",
    "    \n",
    "    # Break the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Run as one script in PyCharm or Visual Studio Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
